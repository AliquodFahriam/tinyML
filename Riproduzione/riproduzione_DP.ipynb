{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "#Dichiaro il path della cartella del dataset\n",
    "import os\n",
    "dataset_folder = \"/home/aliquodfahriam/tinyML/CMAPSS/CMAPSS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sensor1', 'sensor2', 'sensor3', 'sensor4', 'sensor5', 'sensor6', 'sensor7', 'sensor8', 'sensor9', 'sensor10', 'sensor11', 'sensor12', 'sensor13', 'sensor14', 'sensor15', 'sensor16', 'sensor17', 'sensor18', 'sensor19', 'sensor20', 'sensor21', 'sensor22']\n"
     ]
    }
   ],
   "source": [
    "#Genero i nomi per le colonne dei sensori\n",
    "sensors = []\n",
    "for i in range(1,23): #Nel readme dice che i sensori dovrebbero essere 26, tuttavia dai dati ne emergono soltanto 21, il 22esimo dovrebbe essere pieno di NaN,\n",
    "                    #Tuttavia mettendo il range da 1 a 22 si crea un warning per cui ci sarebbe una perdita di informazione che non sarebbe desiderabile.  \n",
    "    sensor = \"sensor\"+str(i)\n",
    "    sensors.append(sensor)\n",
    "\n",
    "print(sensors)\n",
    "\n",
    "del i, sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_FD001.txt', 'train_FD002.txt', 'train_FD003.txt', 'train_FD004.txt']\n",
      "['test_FD001.txt', 'test_FD002.txt', 'test_FD003.txt', 'test_FD004.txt']\n",
      "['unit_number', 'time_cycle', 'op_setting1', 'op_setting2', 'op_setting3', 'sensor1', 'sensor2', 'sensor3', 'sensor4', 'sensor5', 'sensor6', 'sensor7', 'sensor8', 'sensor9', 'sensor10', 'sensor11', 'sensor12', 'sensor13', 'sensor14', 'sensor15', 'sensor16', 'sensor17', 'sensor18', 'sensor19', 'sensor20', 'sensor21', 'sensor22']\n"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "test = []\n",
    "names_train = ['train1', 'train2', 'train3', 'train4']\n",
    "names_test = ['test1', 'test2', 'test3', 'test4']\n",
    "\n",
    "files = os.listdir(dataset_folder)\n",
    "train_files = [file for file in files if file.startswith('train')]\n",
    "test_files = [file for file in files if file.startswith('test')]\n",
    "# print(train_files)\n",
    "# print(test_files)\n",
    "train_files.sort()\n",
    "test_files.sort()\n",
    "print(train_files)\n",
    "print(test_files)\n",
    "\n",
    "colnames = [\"unit_number\", \"time_cycle\", \"op_setting1\", \"op_setting2\", \"op_setting3\"]\n",
    "\n",
    "for sensor in sensors:\n",
    "    colnames.append(sensor)\n",
    "\n",
    "\n",
    "for file in train_files: \n",
    "    df = pd.read_csv(dataset_folder+\"/\"+file, delimiter=' ', index_col=False, names=colnames)\n",
    "    train.append(df)\n",
    "\n",
    "df = train[0]\n",
    "\n",
    "print(colnames)\n",
    "\n",
    "#df = pd.read_csv(dataset_folder+\"/\"+train_files[3], delimiter=' ', index_col=False, names=colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tutti i valori sono zero nel dataframe di posto 1\n",
      "Tutti i valori sono zero nel dataframe di posto 2\n",
      "Tutti i valori sono zero nel dataframe di posto 3\n",
      "Tutti i valori sono zero nel dataframe di posto 4\n"
     ]
    }
   ],
   "source": [
    "## Proviamo a rimuovere gli NaN dai vari dataframe per capire se c'è qualche valore fuori posto in qualche riga.\n",
    "\n",
    "for df in train: \n",
    "    df = df.fillna(value=0, inplace=True)\n",
    "\n",
    "df = train[0]\n",
    "\n",
    "counter = 0\n",
    "for df in train:\n",
    "    counter += 1 \n",
    "    value = (df['sensor22'] != 0).any()\n",
    "    if value: \n",
    "        print(\"Ci sono valori diversi da zero nel dataframe di posto \"+ str(counter))\n",
    "    else:\n",
    "        print(\"Tutti i valori sono zero nel dataframe di posto \"+str(counter))\n",
    "\n",
    "#Comprendo da questo che posso procedere a rimuovere la colonna sensor22 da tutti i dataframe in train: \n",
    "for df in train: \n",
    "    df.drop('sensor22', axis=1, inplace=True)\n",
    "\n",
    "df = train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Sensori con valori costanti\n",
    "Nel papper in esame viene fatto notare come alcuni sensori riportino valori costanti e quindi siano inutili ai fini del nostro esame. Procediamo a verificare che ciò è vero e capiamo se è corretto eliminarli o meno\n",
    "\n",
    "I sensori da controllare sono: \n",
    "- Numero 1\n",
    "- Numero 5 \n",
    "- Numero 6\n",
    "- Numero 10 \n",
    "- Numero 16 \n",
    "- Numero 18 \n",
    "- Numero 19 \n",
    "- Numero 21 \n",
    "\n",
    "\n",
    "Da una prima osservazione si nota come non sia possibile tracciare un modello comune per tutti i dataset di training e si debba quindi ricorrere a una preparazione dei dati più *raffinata* che tenga conto del numero di valori per ogni colonna contenente valori appartenenti ad ogni sensore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = train[0]\n",
    "# df1 = train[1]\n",
    "# df2 = train[2]\n",
    "# df3 = train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_list = []\n",
    "unique_values_per_df = []\n",
    "for dataframe in train: \n",
    "    for sensor in sensors: \n",
    "        unique_values_frame = dataframe[sensor].unique()\n",
    "        unique_values_per_df.append(unique_values_frame)\n",
    "    \n",
    "    unique_values_list.append(unique_values_per_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variabile *unique_values_list* è composta da 84 colonne poiché la variabile *unique_values_per_df* è composta da 21 colonne, le quali sono proprio quelle dei sensori. Ogni 21 colonne quindi si cambia dataframe.\n",
    "\n",
    "Operando in modulo 21 possiamo dividere la lista in 3 liste separate per ricavare in maniera più ordinata i dati dei valori unici per colonna. \n",
    "Saremo così in grado di comprendere se è possibile eliminare gli stessi sensori per ogni dataframe o se ognuno di essi ha bisogno di particolare attenzione.\n",
    "\n",
    "Il passo successivo sarà la normalizzazione dei dataframe tramite un operatore di MinMax Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
