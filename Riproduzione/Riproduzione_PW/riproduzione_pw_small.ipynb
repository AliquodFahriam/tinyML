{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "dataset_folder = '../dataset_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = ['sensor2', 'sensor3', 'sensor4','sensor7','sensor8','sensor9','sensor11','sensor12','sensor13','sensor14',\n",
    "           'sensor15','sensor17','sensor20', 'sensor21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_number</th>\n",
       "      <th>time_cycle</th>\n",
       "      <th>op_setting1</th>\n",
       "      <th>op_setting2</th>\n",
       "      <th>op_setting3</th>\n",
       "      <th>RUL</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor11</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor17</th>\n",
       "      <th>sensor20</th>\n",
       "      <th>sensor21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0.355972</td>\n",
       "      <td>0.370523</td>\n",
       "      <td>0.308580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.204233</td>\n",
       "      <td>0.348571</td>\n",
       "      <td>0.231279</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.239116</td>\n",
       "      <td>0.647755</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.559524</td>\n",
       "      <td>0.446331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>0.388759</td>\n",
       "      <td>0.399100</td>\n",
       "      <td>0.309360</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.202431</td>\n",
       "      <td>0.308571</td>\n",
       "      <td>0.236882</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.278567</td>\n",
       "      <td>0.685659</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.534836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.313817</td>\n",
       "      <td>0.353298</td>\n",
       "      <td>0.445398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664706</td>\n",
       "      <td>0.241484</td>\n",
       "      <td>0.302857</td>\n",
       "      <td>0.217015</td>\n",
       "      <td>0.636905</td>\n",
       "      <td>0.264526</td>\n",
       "      <td>0.564462</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.458577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.487119</td>\n",
       "      <td>0.417107</td>\n",
       "      <td>0.237285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.215326</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.240448</td>\n",
       "      <td>0.684524</td>\n",
       "      <td>0.245612</td>\n",
       "      <td>0.558909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.470238</td>\n",
       "      <td>0.391966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0.196721</td>\n",
       "      <td>0.476218</td>\n",
       "      <td>0.321217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.268799</td>\n",
       "      <td>0.262857</td>\n",
       "      <td>0.245033</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.252109</td>\n",
       "      <td>0.556736</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.577381</td>\n",
       "      <td>0.543371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_number  time_cycle  op_setting1  op_setting2  op_setting3    RUL  \\\n",
       "0          1.0         1.0      -0.0005       0.0004        100.0  258.0   \n",
       "1          1.0         2.0       0.0008      -0.0003        100.0  257.0   \n",
       "2          1.0         3.0      -0.0014      -0.0002        100.0  256.0   \n",
       "3          1.0         4.0      -0.0020       0.0001        100.0  255.0   \n",
       "4          1.0         5.0       0.0016       0.0000        100.0  254.0   \n",
       "\n",
       "    sensor2   sensor3   sensor4  sensor6  ...   sensor8   sensor9  sensor11  \\\n",
       "0  0.355972  0.370523  0.308580      1.0  ...  0.623529  0.204233  0.348571   \n",
       "1  0.388759  0.399100  0.309360      1.0  ...  0.647059  0.202431  0.308571   \n",
       "2  0.313817  0.353298  0.445398      1.0  ...  0.664706  0.241484  0.302857   \n",
       "3  0.487119  0.417107  0.237285      1.0  ...  0.647059  0.215326  0.314286   \n",
       "4  0.196721  0.476218  0.321217      1.0  ...  0.670588  0.268799  0.262857   \n",
       "\n",
       "   sensor12  sensor13  sensor14  sensor15  sensor17  sensor20  sensor21  \n",
       "0  0.231279  0.642857  0.239116  0.647755  0.272727  0.559524  0.446331  \n",
       "1  0.236882  0.654762  0.278567  0.685659  0.363636  0.488095  0.534836  \n",
       "2  0.217015  0.636905  0.264526  0.564462  0.272727  0.404762  0.458577  \n",
       "3  0.240448  0.684524  0.245612  0.558909  0.363636  0.470238  0.391966  \n",
       "4  0.245033  0.654762  0.252109  0.556736  0.363636  0.577381  0.543371  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = []\n",
    "files = os.listdir(dataset_folder)\n",
    "train_files = [file for file in files if file.startswith('scaled')]\n",
    "\n",
    "for file in files: \n",
    "    path_to_file = dataset_folder + '/'+file\n",
    "    df = pd.read_csv(path_to_file, index_col=0) #index_col = 0 perché sennò viene aggiunta la colonna unnamed. \n",
    "    train.append(df)\n",
    "\n",
    "train[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La seguente funzione *process_targets* è la cosiddetta funzione **lineare a tratti** di cui parliamo estensivamente all'interno del readme ci permette dunque di calcolare il valore della RUL da assegnare ad ogni elemento del dataset. \n",
    "La funzione prende in input la lunghezza totale dei dati e la *\"early_rul\"* la quale rappresenta il valore massimo possibile di RUL (imponiamo ciò poiché come descritto dalla letteratura dovrebbe permettere alla rete di comprendere meglio quando il componente è in salute o meno), il quale poi viene decrementato in maniera lineare quando la *\"data_length\"* supera il valore di *early_rul*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_targets(data_length, early_rul = None):\n",
    "    if early_rul == None:\n",
    "        return np.arange(data_length-1, -1, -1)\n",
    "    else:\n",
    "        early_rul_duration = data_length - early_rul\n",
    "        if early_rul_duration <= 0:\n",
    "            return np.arange(data_length-1, -1, -1)\n",
    "        else:\n",
    "            return np.append(early_rul*np.ones(shape = (early_rul_duration,)), np.arange(early_rul-1, -1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*process_input_data_with_targets* è invece la funzione addetta a \"sistemare\" i valori all'interno delle loro proprie sequenze di *window_length* valori. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input_data_with_targets(input_data, target_data = None, window_length = 1, shift = 1):\n",
    "    #Viene calcolato il numero di batch che saranno generati sulla base della grandezza dell'input \n",
    "    num_batches = int(np.floor((len(input_data) - window_length)/shift)) + 1\n",
    "    \n",
    "    #Si recupera il numero di features all'interno del dataframe\n",
    "    num_features = input_data.shape[1]\n",
    "    '''\n",
    "    Qui, viene inizializzata una matrice output_data con valori NaN, che rappresenta i dati di output che verranno generati dalla funzione. \n",
    "    La matrice è inizialmente creata come una matrice 3D con dimensioni (num_batches, window_length, num_features) per contenere i batch di dati di input.\n",
    "    '''\n",
    "    output_data = np.repeat(np.nan, repeats = num_batches * window_length * num_features).reshape(num_batches, window_length,\n",
    "                                                                                                  num_features)\n",
    "    \n",
    "    #Verfico che i labels siano stati forniti\n",
    "    if target_data is None:\n",
    "        \n",
    "        #Iteriamo attraverso i batch e copiamo le finestre temporali corrispondenti dai dati di input input_data nella matrice output_data. \n",
    "        #L'output sarà quindi una matrice 3D con i batch di dati di input.\n",
    "\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "        return output_data\n",
    "    else:\n",
    "        output_targets = np.repeat(np.nan, repeats = num_batches)\n",
    "        #Nel caso in cui i dati siano forniti semplicemente facciamo la stessa cosa per i dati di target\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "            output_targets[batch] = target_data[(shift*batch + (window_length-1))] #Differente perché i dati di target sono formattati in altra maniera.\n",
    "        return output_data, output_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurazione\n",
    "\n",
    "window_length = 30 #Lunghezza delle sequenze\n",
    "shift = 1\n",
    "early_rul = 125 #100 è il valore utilizzato comunemente dallo stato dell'arte             \n",
    "processed_train_data = []\n",
    "processed_train_targets = []\n",
    "\n",
    "FD0001 = train[0]\n",
    "unit_number_col = FD0001['unit_number']\n",
    "num_train_machines_FD0001 = len(FD0001['unit_number'].unique())\n",
    "FD0001 = FD0001[sensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_FD0001 = pd.concat([unit_number_col, FD0001], axis= 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_number</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor11</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor17</th>\n",
       "      <th>sensor20</th>\n",
       "      <th>sensor21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.355972</td>\n",
       "      <td>0.370523</td>\n",
       "      <td>0.308580</td>\n",
       "      <td>0.208812</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.204233</td>\n",
       "      <td>0.348571</td>\n",
       "      <td>0.231279</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.239116</td>\n",
       "      <td>0.647755</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.559524</td>\n",
       "      <td>0.446331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388759</td>\n",
       "      <td>0.399100</td>\n",
       "      <td>0.309360</td>\n",
       "      <td>0.236590</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.202431</td>\n",
       "      <td>0.308571</td>\n",
       "      <td>0.236882</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.278567</td>\n",
       "      <td>0.685659</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.534836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.313817</td>\n",
       "      <td>0.353298</td>\n",
       "      <td>0.445398</td>\n",
       "      <td>0.230843</td>\n",
       "      <td>0.664706</td>\n",
       "      <td>0.241484</td>\n",
       "      <td>0.302857</td>\n",
       "      <td>0.217015</td>\n",
       "      <td>0.636905</td>\n",
       "      <td>0.264526</td>\n",
       "      <td>0.564462</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.458577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.487119</td>\n",
       "      <td>0.417107</td>\n",
       "      <td>0.237285</td>\n",
       "      <td>0.268199</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.215326</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.240448</td>\n",
       "      <td>0.684524</td>\n",
       "      <td>0.245612</td>\n",
       "      <td>0.558909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.470238</td>\n",
       "      <td>0.391966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.196721</td>\n",
       "      <td>0.476218</td>\n",
       "      <td>0.321217</td>\n",
       "      <td>0.245690</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.268799</td>\n",
       "      <td>0.262857</td>\n",
       "      <td>0.245033</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.252109</td>\n",
       "      <td>0.556736</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.577381</td>\n",
       "      <td>0.543371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_number   sensor2   sensor3   sensor4   sensor7   sensor8   sensor9  \\\n",
       "0          1.0  0.355972  0.370523  0.308580  0.208812  0.623529  0.204233   \n",
       "1          1.0  0.388759  0.399100  0.309360  0.236590  0.647059  0.202431   \n",
       "2          1.0  0.313817  0.353298  0.445398  0.230843  0.664706  0.241484   \n",
       "3          1.0  0.487119  0.417107  0.237285  0.268199  0.647059  0.215326   \n",
       "4          1.0  0.196721  0.476218  0.321217  0.245690  0.670588  0.268799   \n",
       "\n",
       "   sensor11  sensor12  sensor13  sensor14  sensor15  sensor17  sensor20  \\\n",
       "0  0.348571  0.231279  0.642857  0.239116  0.647755  0.272727  0.559524   \n",
       "1  0.308571  0.236882  0.654762  0.278567  0.685659  0.363636  0.488095   \n",
       "2  0.302857  0.217015  0.636905  0.264526  0.564462  0.272727  0.404762   \n",
       "3  0.314286  0.240448  0.684524  0.245612  0.558909  0.363636  0.470238   \n",
       "4  0.262857  0.245033  0.654762  0.252109  0.556736  0.363636  0.577381   \n",
       "\n",
       "   sensor21  \n",
       "0  0.446331  \n",
       "1  0.534836  \n",
       "2  0.458577  \n",
       "3  0.391966  \n",
       "4  0.543371  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_FD0001.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in np.arange(1, num_train_machines_FD0001 + 1):\n",
    "    temp_train_data = new_FD0001[new_FD0001['unit_number'] == i].drop(columns = ['unit_number']).values\n",
    "    \n",
    "    # Verify if data of given window length can be extracted from training data\n",
    "    if (len(temp_train_data) < window_length):\n",
    "        print(\"Train engine {} doesn't have enough data for window_length of {}\".format(i, window_length))\n",
    "        raise AssertionError(\"Window length is larger than number of data points for some engines. \"\n",
    "                             \"Try decreasing window length.\")\n",
    "        \n",
    "    temp_train_targets = process_targets(data_length = temp_train_data.shape[0], early_rul = early_rul)\n",
    "    data_for_a_machine, targets_for_a_machine = process_input_data_with_targets(temp_train_data, temp_train_targets, \n",
    "                                                                                window_length = window_length, shift = shift)\n",
    "    \n",
    "    processed_train_data.append(data_for_a_machine)\n",
    "    processed_train_targets.append(targets_for_a_machine)\n",
    "\n",
    "processed_train_data = np.concatenate(processed_train_data)\n",
    "processed_train_targets = np.concatenate(processed_train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed trianing data shape:  (21820, 30, 14)\n",
      "Processed training ruls shape:  (21820,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Processed trianing data shape: \", processed_train_data.shape)\n",
    "print(\"Processed training ruls shape: \", processed_train_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(processed_train_data, processed_train_targets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-02 12:28:21.914010: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-02 12:28:22.559348: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.2/lib64:/usr/local/cuda-11.2/extras/CUPTI/lib64:/home/aliquodfahriam/miniconda3/envs/tensorflowEnv/lib/\n",
      "2023-10-02 12:28:22.559424: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.2/lib64:/usr/local/cuda-11.2/extras/CUPTI/lib64:/home/aliquodfahriam/miniconda3/envs/tensorflowEnv/lib/\n",
      "2023-10-02 12:28:22.559430: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "import tensorflow as tf \n",
    "import math \n",
    "\n",
    "@tf.function\n",
    "def custom_loss2(y_true, y_pred):\n",
    "    alpha = 0.2\n",
    "    difference = y_pred - y_true\n",
    "    squared_difference = tf.square(y_pred - y_true)\n",
    "    \n",
    "    # Calcola la loss per ciascun elemento\n",
    "    loss = tf.where(difference < 0, 2 * alpha * squared_difference, 2 * (alpha + (1 - 2 * alpha)) * squared_difference)\n",
    "    \n",
    "    # Calcola la media delle loss\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "@tf.function\n",
    "def custom_score(y_true, y_pred):\n",
    "    d_i = y_pred - y_true\n",
    "    #esponente = tf.where(d_i < 0, 1.0 / (d_i / 13.0), d_i / 10.0)\n",
    "    sum = tf.reduce_sum(tf.where(d_i < 0, tf.exp(-d_i/13)-1, tf.exp(d_i/10)-1)) #prova\n",
    "    #sum = tf.reduce_sum(tf.exp(esponente) - 1.0)\n",
    "    return sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "#Replica della rete neurale proposta come \"small LSTM\"\n",
    "def createLSTMsmallModel(l1Nodes, l2Nodes, d1Nodes, d2Nodes, input_shape):\n",
    "    # input layer\n",
    "    lstm1 = LSTM(l1Nodes, input_shape=input_shape,activation='tanh', return_sequences=True, kernel_regularizer=regularizers.l2(0.1))\n",
    "    \n",
    "    lstm2 = LSTM(l2Nodes, return_sequences=True, activation='tanh', kernel_regularizer=regularizers.l2(0.1))    \n",
    "    flatten = Flatten()\n",
    "    dense1 = Dense(d1Nodes, activation='relu', kernel_regularizer=regularizers.l2(0.1))\n",
    "    dense2 = Dense(d2Nodes, activation='relu', kernel_regularizer=regularizers.l2(0.1))\n",
    "    \n",
    "    # output layer\n",
    "    outL = Dense(1, activation='relu', kernel_regularizer=regularizers.l2(0.1))\n",
    "    \n",
    "    #layers\n",
    "    layers = [lstm1, lstm2,flatten,  dense1, dense2, outL]\n",
    "    model = Sequential(layers)\n",
    "    #Abbiamo aggiunto le nostre funzioni di loss e accuracy definite precedentemente\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer=optimizer, loss=custom_loss2, metrics = [custom_score] )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-02 12:28:23.042520: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-02 12:28:23.049675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-02 12:28:23.050055: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-02 12:28:23.050604: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-02 12:28:23.051905: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-02 12:28:23.052205: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-02 12:28:23.052383: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-02 12:28:23.535447: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-02 12:28:23.535760: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-02 12:28:23.535974: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-02 12:28:23.536102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 274 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "LSTMsmallModel = createLSTMsmallModel(60, 30, 30, 15, (30, 14)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    elif epoch >= 10 and epoch < 20 :\n",
    "        return 0.001\n",
    "    elif epoch >= 20 and epoch < 30: \n",
    "        return 0.0001\n",
    "    elif epoch >= 30: \n",
    "        return 0.00001\n",
    "    else: \n",
    "        return 0.01; \n",
    "    \n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model, save_model\n",
    "\n",
    "EPOCHS = 50 #100 / 80 / 150 \n",
    "\n",
    "path_small = './models/LSTMsmall/FD0001_scoreFixed'\n",
    "\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    path_small,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=5,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-02 12:28:26.679868: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-10-02 12:28:26.738009: E tensorflow/compiler/xla/stream_executor/dnn.cc:887] CUDNN_STATUS_EXECUTION_FAILED\n",
      "in tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(2112): 'cudnnRNNForwardTraining( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, input_desc.handles(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), rnn_desc.params_handle(), params.opaque(), output_desc.handles(), output_data->opaque(), output_h_desc.handle(), output_h_data->opaque(), output_c_desc.handle(), output_c_data->opaque(), workspace.opaque(), workspace.size(), reserve_space.opaque(), reserve_space.size())'\n",
      "2023-10-02 12:28:26.738066: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at cudnn_rnn_ops.cc:1564 : INTERNAL: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 14, 60, 1, 30, 256, 60] \n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nFailed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 14, 60, 1, 30, 256, 60] \n\t [[{{node CudnnRNN}}]]\n\t [[sequential/lstm/PartitionedCall]] [Op:__inference_train_function_5847]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/aliquodfahriam/tinyML/Riproduzione/Riproduzione_PW/riproduzione_pw_small.ipynb Cella 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/aliquodfahriam/tinyML/Riproduzione/Riproduzione_PW/riproduzione_pw_small.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history_small \u001b[39m=\u001b[39m LSTMsmallModel\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aliquodfahriam/tinyML/Riproduzione/Riproduzione_PW/riproduzione_pw_small.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     X_train, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aliquodfahriam/tinyML/Riproduzione/Riproduzione_PW/riproduzione_pw_small.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     y_train, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aliquodfahriam/tinyML/Riproduzione/Riproduzione_PW/riproduzione_pw_small.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(X_val, y_val), \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aliquodfahriam/tinyML/Riproduzione/Riproduzione_PW/riproduzione_pw_small.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     epochs \u001b[39m=\u001b[39;49m EPOCHS,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aliquodfahriam/tinyML/Riproduzione/Riproduzione_PW/riproduzione_pw_small.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     batch_size \u001b[39m=\u001b[39;49m \u001b[39m256\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aliquodfahriam/tinyML/Riproduzione/Riproduzione_PW/riproduzione_pw_small.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     use_multiprocessing \u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aliquodfahriam/tinyML/Riproduzione/Riproduzione_PW/riproduzione_pw_small.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[model_checkpoint, lr_scheduler])\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflowEnv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflowEnv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nFailed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 14, 60, 1, 30, 256, 60] \n\t [[{{node CudnnRNN}}]]\n\t [[sequential/lstm/PartitionedCall]] [Op:__inference_train_function_5847]"
     ]
    }
   ],
   "source": [
    "history_small = LSTMsmallModel.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data=(X_val, y_val), \n",
    "    epochs = EPOCHS,\n",
    "    batch_size = 256,\n",
    "    use_multiprocessing =True, \n",
    "    callbacks=[model_checkpoint, lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
