{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "dataset_folder = '../dataset_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = ['sensor2', 'sensor3', 'sensor4','sensor7','sensor8','sensor9','sensor11','sensor12','sensor13','sensor14',\n",
    "           'sensor15','sensor17','sensor20', 'sensor21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_number</th>\n",
       "      <th>time_cycle</th>\n",
       "      <th>op_setting1</th>\n",
       "      <th>op_setting2</th>\n",
       "      <th>op_setting3</th>\n",
       "      <th>RUL</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor11</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor17</th>\n",
       "      <th>sensor20</th>\n",
       "      <th>sensor21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0.355972</td>\n",
       "      <td>0.370523</td>\n",
       "      <td>0.308580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.204233</td>\n",
       "      <td>0.348571</td>\n",
       "      <td>0.231279</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.239116</td>\n",
       "      <td>0.647755</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.559524</td>\n",
       "      <td>0.446331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>0.388759</td>\n",
       "      <td>0.399100</td>\n",
       "      <td>0.309360</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.202431</td>\n",
       "      <td>0.308571</td>\n",
       "      <td>0.236882</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.278567</td>\n",
       "      <td>0.685659</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.534836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.313817</td>\n",
       "      <td>0.353298</td>\n",
       "      <td>0.445398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664706</td>\n",
       "      <td>0.241484</td>\n",
       "      <td>0.302857</td>\n",
       "      <td>0.217015</td>\n",
       "      <td>0.636905</td>\n",
       "      <td>0.264526</td>\n",
       "      <td>0.564462</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.458577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.487119</td>\n",
       "      <td>0.417107</td>\n",
       "      <td>0.237285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.215326</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.240448</td>\n",
       "      <td>0.684524</td>\n",
       "      <td>0.245612</td>\n",
       "      <td>0.558909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.470238</td>\n",
       "      <td>0.391966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0.196721</td>\n",
       "      <td>0.476218</td>\n",
       "      <td>0.321217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.268799</td>\n",
       "      <td>0.262857</td>\n",
       "      <td>0.245033</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.252109</td>\n",
       "      <td>0.556736</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.577381</td>\n",
       "      <td>0.543371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_number  time_cycle  op_setting1  op_setting2  op_setting3    RUL  \\\n",
       "0          1.0         1.0      -0.0005       0.0004        100.0  258.0   \n",
       "1          1.0         2.0       0.0008      -0.0003        100.0  257.0   \n",
       "2          1.0         3.0      -0.0014      -0.0002        100.0  256.0   \n",
       "3          1.0         4.0      -0.0020       0.0001        100.0  255.0   \n",
       "4          1.0         5.0       0.0016       0.0000        100.0  254.0   \n",
       "\n",
       "    sensor2   sensor3   sensor4  sensor6  ...   sensor8   sensor9  sensor11  \\\n",
       "0  0.355972  0.370523  0.308580      1.0  ...  0.623529  0.204233  0.348571   \n",
       "1  0.388759  0.399100  0.309360      1.0  ...  0.647059  0.202431  0.308571   \n",
       "2  0.313817  0.353298  0.445398      1.0  ...  0.664706  0.241484  0.302857   \n",
       "3  0.487119  0.417107  0.237285      1.0  ...  0.647059  0.215326  0.314286   \n",
       "4  0.196721  0.476218  0.321217      1.0  ...  0.670588  0.268799  0.262857   \n",
       "\n",
       "   sensor12  sensor13  sensor14  sensor15  sensor17  sensor20  sensor21  \n",
       "0  0.231279  0.642857  0.239116  0.647755  0.272727  0.559524  0.446331  \n",
       "1  0.236882  0.654762  0.278567  0.685659  0.363636  0.488095  0.534836  \n",
       "2  0.217015  0.636905  0.264526  0.564462  0.272727  0.404762  0.458577  \n",
       "3  0.240448  0.684524  0.245612  0.558909  0.363636  0.470238  0.391966  \n",
       "4  0.245033  0.654762  0.252109  0.556736  0.363636  0.577381  0.543371  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = []\n",
    "files = os.listdir(dataset_folder)\n",
    "train_files = [file for file in files if file.startswith('scaled')]\n",
    "\n",
    "for file in files: \n",
    "    path_to_file = dataset_folder + '/'+file\n",
    "    df = pd.read_csv(path_to_file, index_col=0) #index_col = 0 perché sennò viene aggiunta la colonna unnamed. \n",
    "    train.append(df)\n",
    "\n",
    "train[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La seguente funzione *process_targets* è la cosiddetta funzione **lineare a tratti** di cui parliamo estensivamente all'interno del readme ci permette dunque di calcolare il valore della RUL da assegnare ad ogni elemento del dataset. \n",
    "La funzione prende in input la lunghezza totale dei dati e la *\"early_rul\"* la quale rappresenta il valore massimo possibile di RUL (imponiamo ciò poiché come descritto dalla letteratura dovrebbe permettere alla rete di comprendere meglio quando il componente è in salute o meno), il quale poi viene decrementato in maniera lineare quando la *\"data_length\"* supera il valore di *early_rul*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_targets(data_length, early_rul = None):\n",
    "    if early_rul == None:\n",
    "        return np.arange(data_length-1, -1, -1)\n",
    "    else:\n",
    "        early_rul_duration = data_length - early_rul\n",
    "        if early_rul_duration <= 0:\n",
    "            return np.arange(data_length-1, -1, -1)\n",
    "        else:\n",
    "            return np.append(early_rul*np.ones(shape = (early_rul_duration,)), np.arange(early_rul-1, -1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*process_input_data_with_targets* è invece la funzione addetta a \"sistemare\" i valori all'interno delle loro proprie sequenze di *window_length* valori. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input_data_with_targets(input_data, target_data = None, window_length = 1, shift = 1):\n",
    "    #Viene calcolato il numero di batch che saranno generati sulla base della grandezza dell'input \n",
    "    num_batches = int(np.floor((len(input_data) - window_length)/shift)) + 1\n",
    "    \n",
    "    #Si recupera il numero di features all'interno del dataframe\n",
    "    num_features = input_data.shape[1]\n",
    "    '''\n",
    "    Qui, viene inizializzata una matrice output_data con valori NaN, che rappresenta i dati di output che verranno generati dalla funzione. \n",
    "    La matrice è inizialmente creata come una matrice 3D con dimensioni (num_batches, window_length, num_features) per contenere i batch di dati di input.\n",
    "    '''\n",
    "    output_data = np.repeat(np.nan, repeats = num_batches * window_length * num_features).reshape(num_batches, window_length,\n",
    "                                                                                                  num_features)\n",
    "    \n",
    "    #Verfico che i labels siano stati forniti\n",
    "    if target_data is None:\n",
    "        \n",
    "        #Iteriamo attraverso i batch e copiamo le finestre temporali corrispondenti dai dati di input input_data nella matrice output_data. \n",
    "        #L'output sarà quindi una matrice 3D con i batch di dati di input.\n",
    "\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "        return output_data\n",
    "    else:\n",
    "        output_targets = np.repeat(np.nan, repeats = num_batches)\n",
    "        #Nel caso in cui i dati siano forniti semplicemente facciamo la stessa cosa per i dati di target\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "            output_targets[batch] = target_data[(shift*batch + (window_length-1))] #Differente perché i dati di target sono formattati in altra maniera.\n",
    "        return output_data, output_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurazione\n",
    "\n",
    "window_length = 30 #Lunghezza delle sequenze\n",
    "shift = 1\n",
    "early_rul = 125 #100 è il valore utilizzato comunemente dallo stato dell'arte             \n",
    "processed_train_data = []\n",
    "processed_train_targets = []\n",
    "\n",
    "FD0001 = train[0]\n",
    "unit_number_col = FD0001['unit_number']\n",
    "num_train_machines_FD0001 = len(FD0001['unit_number'].unique())\n",
    "FD0001 = FD0001[sensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_FD0001 = pd.concat([unit_number_col, FD0001], axis= 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_number</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor11</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor17</th>\n",
       "      <th>sensor20</th>\n",
       "      <th>sensor21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.355972</td>\n",
       "      <td>0.370523</td>\n",
       "      <td>0.308580</td>\n",
       "      <td>0.208812</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.204233</td>\n",
       "      <td>0.348571</td>\n",
       "      <td>0.231279</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.239116</td>\n",
       "      <td>0.647755</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.559524</td>\n",
       "      <td>0.446331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388759</td>\n",
       "      <td>0.399100</td>\n",
       "      <td>0.309360</td>\n",
       "      <td>0.236590</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.202431</td>\n",
       "      <td>0.308571</td>\n",
       "      <td>0.236882</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.278567</td>\n",
       "      <td>0.685659</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.534836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.313817</td>\n",
       "      <td>0.353298</td>\n",
       "      <td>0.445398</td>\n",
       "      <td>0.230843</td>\n",
       "      <td>0.664706</td>\n",
       "      <td>0.241484</td>\n",
       "      <td>0.302857</td>\n",
       "      <td>0.217015</td>\n",
       "      <td>0.636905</td>\n",
       "      <td>0.264526</td>\n",
       "      <td>0.564462</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.458577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.487119</td>\n",
       "      <td>0.417107</td>\n",
       "      <td>0.237285</td>\n",
       "      <td>0.268199</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.215326</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.240448</td>\n",
       "      <td>0.684524</td>\n",
       "      <td>0.245612</td>\n",
       "      <td>0.558909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.470238</td>\n",
       "      <td>0.391966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.196721</td>\n",
       "      <td>0.476218</td>\n",
       "      <td>0.321217</td>\n",
       "      <td>0.245690</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.268799</td>\n",
       "      <td>0.262857</td>\n",
       "      <td>0.245033</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.252109</td>\n",
       "      <td>0.556736</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.577381</td>\n",
       "      <td>0.543371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_number   sensor2   sensor3   sensor4   sensor7   sensor8   sensor9  \\\n",
       "0          1.0  0.355972  0.370523  0.308580  0.208812  0.623529  0.204233   \n",
       "1          1.0  0.388759  0.399100  0.309360  0.236590  0.647059  0.202431   \n",
       "2          1.0  0.313817  0.353298  0.445398  0.230843  0.664706  0.241484   \n",
       "3          1.0  0.487119  0.417107  0.237285  0.268199  0.647059  0.215326   \n",
       "4          1.0  0.196721  0.476218  0.321217  0.245690  0.670588  0.268799   \n",
       "\n",
       "   sensor11  sensor12  sensor13  sensor14  sensor15  sensor17  sensor20  \\\n",
       "0  0.348571  0.231279  0.642857  0.239116  0.647755  0.272727  0.559524   \n",
       "1  0.308571  0.236882  0.654762  0.278567  0.685659  0.363636  0.488095   \n",
       "2  0.302857  0.217015  0.636905  0.264526  0.564462  0.272727  0.404762   \n",
       "3  0.314286  0.240448  0.684524  0.245612  0.558909  0.363636  0.470238   \n",
       "4  0.262857  0.245033  0.654762  0.252109  0.556736  0.363636  0.577381   \n",
       "\n",
       "   sensor21  \n",
       "0  0.446331  \n",
       "1  0.534836  \n",
       "2  0.458577  \n",
       "3  0.391966  \n",
       "4  0.543371  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_FD0001.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in np.arange(1, num_train_machines_FD0001 + 1):\n",
    "    temp_train_data = new_FD0001[new_FD0001['unit_number'] == i].drop(columns = ['unit_number']).values\n",
    "    \n",
    "    # Verify if data of given window length can be extracted from training data\n",
    "    if (len(temp_train_data) < window_length):\n",
    "        print(\"Train engine {} doesn't have enough data for window_length of {}\".format(i, window_length))\n",
    "        raise AssertionError(\"Window length is larger than number of data points for some engines. \"\n",
    "                             \"Try decreasing window length.\")\n",
    "        \n",
    "    temp_train_targets = process_targets(data_length = temp_train_data.shape[0], early_rul = early_rul)\n",
    "    data_for_a_machine, targets_for_a_machine = process_input_data_with_targets(temp_train_data, temp_train_targets, \n",
    "                                                                                window_length = window_length, shift = shift)\n",
    "    \n",
    "    processed_train_data.append(data_for_a_machine)\n",
    "    processed_train_targets.append(targets_for_a_machine)\n",
    "\n",
    "processed_train_data = np.concatenate(processed_train_data)\n",
    "processed_train_targets = np.concatenate(processed_train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed trianing data shape:  (21820, 30, 14)\n",
      "Processed training ruls shape:  (21820,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Processed trianing data shape: \", processed_train_data.shape)\n",
    "print(\"Processed training ruls shape: \", processed_train_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(processed_train_data, processed_train_targets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 01:34:25.125078: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-03 01:34:27.108426: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.2/lib64:/usr/local/cuda-11.2/extras/CUPTI/lib64:/home/aliquodfahriam/miniconda3/envs/tensorflowEnv/lib/\n",
      "2023-10-03 01:34:27.109094: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.2/lib64:/usr/local/cuda-11.2/extras/CUPTI/lib64:/home/aliquodfahriam/miniconda3/envs/tensorflowEnv/lib/\n",
      "2023-10-03 01:34:27.109122: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "import tensorflow as tf \n",
    "import math \n",
    "\n",
    "@tf.function\n",
    "def custom_loss2(y_true, y_pred):\n",
    "    alpha = 0.2\n",
    "    difference = y_pred - y_true\n",
    "    squared_difference = tf.square(y_pred - y_true)\n",
    "    \n",
    "    # Calcola la loss per ciascun elemento\n",
    "    loss = tf.where(difference < 0, 2 * alpha * squared_difference, 2 * (alpha + (1 - 2 * alpha)) * squared_difference)\n",
    "    \n",
    "    # Calcola la media delle loss\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "@tf.function\n",
    "def custom_score(y_true, y_pred):\n",
    "    d_i = y_pred - y_true\n",
    "    #esponente = tf.where(d_i < 0, 1.0 / (d_i / 13.0), d_i / 10.0)\n",
    "    sum = tf.reduce_sum(tf.where(d_i < 0, tf.exp(-d_i/13)-1, tf.exp(d_i/10)-1)) #prova\n",
    "    #sum = tf.reduce_sum(tf.exp(esponente) - 1.0)\n",
    "    return sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "#Replica della rete neurale proposta come \"small LSTM\"\n",
    "def createLSTMsmallModel(l1Nodes, l2Nodes, d1Nodes, d2Nodes, input_shape):\n",
    "    # input layer\n",
    "    lstm1 = LSTM(l1Nodes, input_shape=input_shape,activation='tanh', return_sequences=True, kernel_regularizer=regularizers.l2(0.1))\n",
    "    \n",
    "    lstm2 = LSTM(l2Nodes, return_sequences=True, activation='tanh', kernel_regularizer=regularizers.l2(0.1))    \n",
    "    flatten = Flatten()\n",
    "    dense1 = Dense(d1Nodes, activation='relu', kernel_regularizer=regularizers.l2(0.1))\n",
    "    dense2 = Dense(d2Nodes, activation='relu', kernel_regularizer=regularizers.l2(0.1))\n",
    "    \n",
    "    # output layer\n",
    "    outL = Dense(1, activation='relu', kernel_regularizer=regularizers.l2(0.1))\n",
    "    \n",
    "    #layers\n",
    "    layers = [lstm1, lstm2,flatten,  dense1, dense2, outL]\n",
    "    model = Sequential(layers)\n",
    "    #Abbiamo aggiunto le nostre funzioni di loss e accuracy definite precedentemente\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer=optimizer, loss=custom_loss2, metrics = [custom_score] )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 01:34:28.388105: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-03 01:34:28.432875: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-03 01:34:28.433760: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-03 01:34:28.435176: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-03 01:34:28.437178: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-03 01:34:28.437642: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-03 01:34:28.438175: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-03 01:34:29.741390: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-03 01:34:29.742292: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-03 01:34:29.742683: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-03 01:34:29.743429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4092 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "LSTMsmallModel = createLSTMsmallModel(60, 30, 30, 15, (30, 14)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    elif epoch >= 10 and epoch < 20 :\n",
    "        return 0.001\n",
    "    elif epoch >= 20 and epoch < 30: \n",
    "        return 0.0001\n",
    "    elif epoch >= 30: \n",
    "        return 0.00001\n",
    "    else: \n",
    "        return 0.01; \n",
    "    \n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model, save_model\n",
    "\n",
    "EPOCHS = 50 #100 / 80 / 150 \n",
    "\n",
    "path_small = './models/LSTMsmall/FD0001_scoreFixed'\n",
    "\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    path_small,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=5,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 01:34:34.127790: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/69 [============================>.] - ETA: 0s - loss: 1433.1656 - custom_score: 92605.6328\n",
      "Epoch 1: val_loss improved from inf to 973.98615, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 13s 120ms/step - loss: 1430.9346 - custom_score: 91283.0547 - val_loss: 973.9861 - val_custom_score: 73284.1719 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 2/50\n",
      "68/69 [============================>.] - ETA: 0s - loss: 438.1898 - custom_score: 5568.0225\n",
      "Epoch 2: val_loss improved from 973.98615 to 345.30621, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 7s 107ms/step - loss: 438.0273 - custom_score: 5498.1680 - val_loss: 345.3062 - val_custom_score: 2280.3567 - lr: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 3/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 339.6969 - custom_score: 2861.1587\n",
      "Epoch 3: val_loss improved from 345.30621 to 279.26331, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 8s 113ms/step - loss: 338.9238 - custom_score: 2810.9297 - val_loss: 279.2633 - val_custom_score: 1949.5112 - lr: 0.0100\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - ETA: 0s - loss: 253.4097 - custom_score: 1572.6671\n",
      "Epoch 4: val_loss improved from 279.26331 to 214.54681, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 7s 108ms/step - loss: 253.4097 - custom_score: 1572.6671 - val_loss: 214.5468 - val_custom_score: 993.2733 - lr: 0.0100\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 5/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 208.6830 - custom_score: 1149.1757\n",
      "Epoch 5: val_loss did not improve from 214.54681\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 208.4174 - custom_score: 1127.8505 - val_loss: 241.1863 - val_custom_score: 1619.8999 - lr: 0.0100\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - ETA: 0s - loss: 200.1997 - custom_score: 1068.4973\n",
      "Epoch 6: val_loss did not improve from 214.54681\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 200.1997 - custom_score: 1068.4973 - val_loss: 241.1365 - val_custom_score: 1702.6472 - lr: 0.0100\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 7/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 183.6087 - custom_score: 964.0254\n",
      "Epoch 7: val_loss improved from 214.54681 to 178.64552, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 7s 110ms/step - loss: 183.3465 - custom_score: 949.7567 - val_loss: 178.6455 - val_custom_score: 930.8464 - lr: 0.0100\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 8/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 179.6153 - custom_score: 933.8301\n",
      "Epoch 8: val_loss improved from 178.64552 to 170.28261, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 7s 109ms/step - loss: 179.6061 - custom_score: 925.0506 - val_loss: 170.2826 - val_custom_score: 839.9889 - lr: 0.0100\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 9/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 166.2340 - custom_score: 851.4120\n",
      "Epoch 9: val_loss did not improve from 170.28261\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 166.3614 - custom_score: 844.7325 - val_loss: 186.0589 - val_custom_score: 687.9890 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "Epoch 10/50\n",
      "66/69 [===========================>..] - ETA: 0s - loss: 179.3111 - custom_score: 962.8380\n",
      "Epoch 10: val_loss improved from 170.28261 to 163.48071, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 8s 111ms/step - loss: 178.8176 - custom_score: 951.9462 - val_loss: 163.4807 - val_custom_score: 659.6433 - lr: 0.0100\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 11/50\n",
      "68/69 [============================>.] - ETA: 0s - loss: 151.1071 - custom_score: 757.2645\n",
      "Epoch 11: val_loss improved from 163.48071 to 153.52078, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 8s 114ms/step - loss: 151.1659 - custom_score: 748.8344 - val_loss: 153.5208 - val_custom_score: 652.5574 - lr: 0.0010\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - ETA: 0s - loss: 147.2643 - custom_score: 728.2935\n",
      "Epoch 12: val_loss improved from 153.52078 to 152.97075, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 8s 114ms/step - loss: 147.2643 - custom_score: 728.2935 - val_loss: 152.9707 - val_custom_score: 631.2836 - lr: 0.0010\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 13/50\n",
      "68/69 [============================>.] - ETA: 0s - loss: 145.0671 - custom_score: 723.4934\n",
      "Epoch 13: val_loss improved from 152.97075 to 146.44130, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 8s 113ms/step - loss: 145.0098 - custom_score: 714.5329 - val_loss: 146.4413 - val_custom_score: 641.4554 - lr: 0.0010\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 14/50\n",
      "68/69 [============================>.] - ETA: 0s - loss: 142.0372 - custom_score: 706.5298\n",
      "Epoch 14: val_loss improved from 146.44130 to 142.29869, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 8s 111ms/step - loss: 141.9998 - custom_score: 697.8291 - val_loss: 142.2987 - val_custom_score: 667.0975 - lr: 0.0010\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - ETA: 0s - loss: 140.1486 - custom_score: 684.9612\n",
      "Epoch 15: val_loss did not improve from 142.29869\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 140.1486 - custom_score: 684.9612 - val_loss: 142.9896 - val_custom_score: 654.1577 - lr: 0.0010\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 16/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 137.8596 - custom_score: 676.1083\n",
      "Epoch 16: val_loss improved from 142.29869 to 138.71233, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 8s 112ms/step - loss: 138.0080 - custom_score: 668.7408 - val_loss: 138.7123 - val_custom_score: 597.6381 - lr: 0.0010\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 17/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 134.5937 - custom_score: 657.5988\n",
      "Epoch 17: val_loss improved from 138.71233 to 135.95273, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 7s 109ms/step - loss: 134.5107 - custom_score: 651.8666 - val_loss: 135.9527 - val_custom_score: 644.7118 - lr: 0.0010\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - ETA: 0s - loss: 132.5616 - custom_score: 638.4352\n",
      "Epoch 18: val_loss did not improve from 135.95273\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 132.5616 - custom_score: 638.4352 - val_loss: 136.9373 - val_custom_score: 707.6448 - lr: 0.0010\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 19/50\n",
      "68/69 [============================>.] - ETA: 0s - loss: 132.1280 - custom_score: 650.0920\n",
      "Epoch 19: val_loss improved from 135.95273 to 133.36453, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 8s 117ms/step - loss: 132.1805 - custom_score: 642.4949 - val_loss: 133.3645 - val_custom_score: 618.5699 - lr: 0.0010\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 20/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 129.5632 - custom_score: 636.5718\n",
      "Epoch 20: val_loss did not improve from 133.36453\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 129.3598 - custom_score: 626.4802 - val_loss: 136.7558 - val_custom_score: 559.8130 - lr: 0.0010\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 21/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 126.8741 - custom_score: 605.8291\n",
      "Epoch 21: val_loss improved from 133.36453 to 130.46185, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 8s 111ms/step - loss: 126.9401 - custom_score: 600.8304 - val_loss: 130.4619 - val_custom_score: 586.7535 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 22/50\n",
      "68/69 [============================>.] - ETA: 0s - loss: 125.1971 - custom_score: 606.6728\n",
      "Epoch 22: val_loss did not improve from 130.46185\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 125.3183 - custom_score: 600.4761 - val_loss: 130.7952 - val_custom_score: 558.3071 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - ETA: 0s - loss: 124.9143 - custom_score: 595.3272\n",
      "Epoch 23: val_loss improved from 130.46185 to 130.41899, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 8s 112ms/step - loss: 124.9143 - custom_score: 595.3272 - val_loss: 130.4190 - val_custom_score: 563.1210 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 24/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 124.7241 - custom_score: 601.6745\n",
      "Epoch 24: val_loss improved from 130.41899 to 129.98982, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 8s 114ms/step - loss: 124.7453 - custom_score: 595.0982 - val_loss: 129.9898 - val_custom_score: 563.5201 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 25/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 124.8204 - custom_score: 600.9101\n",
      "Epoch 25: val_loss improved from 129.98982 to 129.94533, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 8s 112ms/step - loss: 124.7003 - custom_score: 592.2192 - val_loss: 129.9453 - val_custom_score: 558.7525 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 26/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 124.3135 - custom_score: 596.6796\n",
      "Epoch 26: val_loss improved from 129.94533 to 129.27142, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 8s 115ms/step - loss: 124.3494 - custom_score: 590.3469 - val_loss: 129.2714 - val_custom_score: 570.7524 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 27/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 124.2666 - custom_score: 598.4335\n",
      "Epoch 27: val_loss did not improve from 129.27142\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 124.2867 - custom_score: 591.9176 - val_loss: 129.5864 - val_custom_score: 574.8082 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 28/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 123.8618 - custom_score: 598.6523\n",
      "Epoch 28: val_loss improved from 129.27142 to 128.82950, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 8s 112ms/step - loss: 124.0883 - custom_score: 592.2486 - val_loss: 128.8295 - val_custom_score: 570.6929 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 29/50\n",
      "68/69 [============================>.] - ETA: 0s - loss: 123.9648 - custom_score: 600.8798\n",
      "Epoch 29: val_loss did not improve from 128.82950\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 123.9985 - custom_score: 593.7154 - val_loss: 129.5285 - val_custom_score: 565.6597 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 30/50\n",
      "68/69 [============================>.] - ETA: 0s - loss: 123.6505 - custom_score: 596.3531\n",
      "Epoch 30: val_loss did not improve from 128.82950\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 123.7233 - custom_score: 589.5132 - val_loss: 129.2965 - val_custom_score: 573.4185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 31/50\n",
      "68/69 [============================>.] - ETA: 0s - loss: 123.3632 - custom_score: 596.9702\n",
      "Epoch 31: val_loss did not improve from 128.82950\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 123.3605 - custom_score: 589.8653 - val_loss: 129.2334 - val_custom_score: 558.3838 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 32/50\n",
      "68/69 [============================>.] - ETA: 0s - loss: 123.2320 - custom_score: 589.1724\n",
      "Epoch 32: val_loss did not improve from 128.82950\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 123.3272 - custom_score: 582.7789 - val_loss: 129.0754 - val_custom_score: 562.0499 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 33/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 123.3293 - custom_score: 595.1577\n",
      "Epoch 33: val_loss did not improve from 128.82950\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 123.2656 - custom_score: 587.9584 - val_loss: 129.0522 - val_custom_score: 560.7014 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 34/50\n",
      "68/69 [============================>.] - ETA: 0s - loss: 123.2453 - custom_score: 592.1791\n",
      "Epoch 34: val_loss did not improve from 128.82950\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 123.2443 - custom_score: 585.3854 - val_loss: 129.0881 - val_custom_score: 560.7870 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 35/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 123.2124 - custom_score: 590.8589\n",
      "Epoch 35: val_loss did not improve from 128.82950\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 123.2269 - custom_score: 584.5043 - val_loss: 129.1134 - val_custom_score: 559.8110 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 36/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 123.0523 - custom_score: 590.9225\n",
      "Epoch 36: val_loss did not improve from 128.82950\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 123.2165 - custom_score: 586.0302 - val_loss: 129.0158 - val_custom_score: 559.8470 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - ETA: 0s - loss: 123.1958 - custom_score: 586.7887\n",
      "Epoch 37: val_loss did not improve from 128.82950\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 123.1958 - custom_score: 586.7887 - val_loss: 129.0163 - val_custom_score: 558.9108 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - ETA: 0s - loss: 123.1881 - custom_score: 587.4654\n",
      "Epoch 38: val_loss did not improve from 128.82950\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 123.1881 - custom_score: 587.4654 - val_loss: 129.1710 - val_custom_score: 554.6323 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 39/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 123.0564 - custom_score: 584.5028\n",
      "Epoch 39: val_loss did not improve from 128.82950\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 123.1620 - custom_score: 580.3047 - val_loss: 128.9305 - val_custom_score: 562.9534 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - ETA: 0s - loss: 123.1498 - custom_score: 585.8914\n",
      "Epoch 40: val_loss did not improve from 128.82950\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 123.1498 - custom_score: 585.8914 - val_loss: 128.9180 - val_custom_score: 562.4476 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 41/50\n",
      "68/69 [============================>.] - ETA: 0s - loss: 123.1676 - custom_score: 591.0998\n",
      "Epoch 41: val_loss did not improve from 128.82950\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 123.1296 - custom_score: 583.9239 - val_loss: 128.9044 - val_custom_score: 562.5103 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 42/50\n",
      "68/69 [============================>.] - ETA: 0s - loss: 123.0962 - custom_score: 592.6509\n",
      "Epoch 42: val_loss did not improve from 128.82950\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 123.1123 - custom_score: 585.5949 - val_loss: 128.8309 - val_custom_score: 564.3314 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 43/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 123.1955 - custom_score: 592.9824\n",
      "Epoch 43: val_loss did not improve from 128.82950\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 123.1223 - custom_score: 586.2181 - val_loss: 128.8446 - val_custom_score: 563.9173 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - ETA: 0s - loss: 123.0643 - custom_score: 586.2908\n",
      "Epoch 44: val_loss did not improve from 128.82950\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 123.0643 - custom_score: 586.2908 - val_loss: 128.9457 - val_custom_score: 557.4367 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 45/50\n",
      "68/69 [============================>.] - ETA: 0s - loss: 123.1208 - custom_score: 594.1741\n",
      "Epoch 45: val_loss did not improve from 128.82950\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 123.0688 - custom_score: 587.1048 - val_loss: 128.8492 - val_custom_score: 560.6633 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 46/50\n",
      "68/69 [============================>.] - ETA: 0s - loss: 123.0060 - custom_score: 586.1745\n",
      "Epoch 46: val_loss did not improve from 128.82950\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 123.0116 - custom_score: 579.4560 - val_loss: 128.8383 - val_custom_score: 564.2963 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - ETA: 0s - loss: 123.0582 - custom_score: 585.4432\n",
      "Epoch 47: val_loss improved from 128.82950 to 128.76054, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 8s 117ms/step - loss: 123.0582 - custom_score: 585.4432 - val_loss: 128.7605 - val_custom_score: 562.7856 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 48/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 123.1762 - custom_score: 596.4161\n",
      "Epoch 48: val_loss did not improve from 128.76054\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 123.0140 - custom_score: 587.7177 - val_loss: 128.8179 - val_custom_score: 559.9338 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 49/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 123.2651 - custom_score: 594.4536\n",
      "Epoch 49: val_loss did not improve from 128.76054\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 122.9682 - custom_score: 586.3901 - val_loss: 128.7680 - val_custom_score: 559.8137 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 50/50\n",
      "67/69 [============================>.] - ETA: 0s - loss: 123.1057 - custom_score: 588.0864\n",
      "Epoch 50: val_loss improved from 128.76054 to 128.67580, saving model to ./models/LSTMsmall/FD0001_scoreFixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/LSTMsmall/FD0001_scoreFixed/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 8s 122ms/step - loss: 122.9703 - custom_score: 581.3926 - val_loss: 128.6758 - val_custom_score: 564.5370 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "history_small = LSTMsmallModel.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data=(X_val, y_val), \n",
    "    epochs = EPOCHS,\n",
    "    batch_size = 256,\n",
    "    use_multiprocessing =True, \n",
    "    callbacks=[model_checkpoint, lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
