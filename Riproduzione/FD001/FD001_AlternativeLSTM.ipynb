{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 09:36:28.696781: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-15 09:36:28.696821: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-15 09:36:28.696839: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-15 09:36:28.705288: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../../CMAPSS/train_FD001.txt\", sep= \"\\s+\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input_data_with_targets(input_data, target_data = None, window_length = 1, shift = 1):\n",
    "    \"\"\"Depending on values of window_length and shift, this function generates batchs of data and targets \n",
    "    from input_data and target_data.\n",
    "    \n",
    "    Number of batches = np.floor((len(input_data) - window_length)/shift) + 1\n",
    "    \n",
    "    **We don't check input dimensions uisng exception handling. So readers should be careful while using these\n",
    "    functions. If input data are not of desired dimension, either error occurs or something undesirable is \n",
    "    produced as output.**\n",
    "    \n",
    "    Arguments:\n",
    "        input_data: input data to function (Must be 2 dimensional)\n",
    "        target_data: input rul values (Must be 1D array)s\n",
    "        window_length: window length of data\n",
    "        shift: Distance by which the window moves for next batch. This is closely related to overlap\n",
    "               between data. For example, if window length is 30 and shift is 1, there is an overlap of \n",
    "               29 data points between two consecutive batches.\n",
    "        \n",
    "    \"\"\"\n",
    "    num_batches = int(np.floor((len(input_data) - window_length)/shift)) + 1\n",
    "    num_features = input_data.shape[1]\n",
    "    output_data = np.repeat(np.nan, repeats = num_batches * window_length * num_features).reshape(num_batches, window_length,\n",
    "                                                                                                  num_features)\n",
    "    if target_data is None:\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "        return output_data\n",
    "    else:\n",
    "        output_targets = np.repeat(np.nan, repeats = num_batches)\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "            output_targets[batch] = target_data[(shift*batch + (window_length-1))]\n",
    "        return output_data, output_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data(test_data_for_an_engine, window_length, shift, num_test_windows = 1):\n",
    "    \"\"\" This function takes test data for an engine as first input. The next two inputs\n",
    "    window_length and shift are same as other functins. \n",
    "    \n",
    "    Finally it takes num_test_windows as the last input. num_test_windows sets how many examplles we\n",
    "    want from test data (from last). By default it extracts only the last example.\n",
    "    \n",
    "    The function return last examples and number of last examples (a scaler) as output. \n",
    "    We need the second output later. If we are extracting more than 1 last examples, we have to \n",
    "    average their prediction results. The second scaler halps us do just that.\n",
    "    \"\"\"\n",
    "    max_num_test_batches = int(np.floor((len(test_data_for_an_engine) - window_length)/shift)) + 1\n",
    "    if max_num_test_batches < num_test_windows:\n",
    "        required_len = (max_num_test_batches -1)* shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, max_num_test_batches\n",
    "    else:\n",
    "        required_len = (num_test_windows - 1) * shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, num_test_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_targets(data_length, early_rul = None):\n",
    "    if early_rul == None:\n",
    "        return np.arange(data_length-1, -1, -1)\n",
    "    else:\n",
    "        early_rul_duration = data_length - early_rul\n",
    "        if early_rul_duration <= 0:\n",
    "            return np.arange(data_length-1, -1, -1)\n",
    "        else:\n",
    "            return np.append(early_rul*np.ones(shape = (early_rul_duration,)), np.arange(early_rul-1, -1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed trianing data shape:  (17731, 30, 14)\n",
      "Processed training ruls shape:  (17731,)\n",
      "Processed test data shape:  (497, 30, 14)\n",
      "True RUL shape:  (100,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"../../CMAPSS/test_FD001.txt\", sep = \"\\s+\", header = None)\n",
    "true_rul = pd.read_csv(\"../../CMAPSS/RUL_FD001.txt\", sep = '\\s+', header = None)\n",
    "\n",
    "window_length = 30 #corretta\n",
    "shift = 1 #corretta\n",
    "early_rul = 125        #corretta    \n",
    "processed_train_data = []\n",
    "processed_train_targets = []\n",
    "\n",
    "# How many test windows to take for each engine. If set to 1 (this is the default), only last window of test data for \n",
    "# each engine is taken. If set to a different number, that many windows from last are taken. \n",
    "# Final output is the average output of all windows.\n",
    "num_test_windows = 5     \n",
    "processed_test_data = []\n",
    "num_test_windows_list = []\n",
    "\n",
    "columns_to_be_dropped = [0,1,2,3,4,5,9,10,14,20,22,23]\n",
    "\n",
    "train_data_first_column = train_data[0]\n",
    "test_data_first_column = test_data[0]\n",
    "\n",
    "# Scale data for all engines\n",
    "scaler = MinMaxScaler(feature_range = (-1,1))\n",
    "train_data = scaler.fit_transform(train_data.drop(columns = columns_to_be_dropped))\n",
    "test_data = scaler.transform(test_data.drop(columns = columns_to_be_dropped))\n",
    "\n",
    "train_data = pd.DataFrame(data = np.c_[train_data_first_column, train_data])\n",
    "test_data = pd.DataFrame(data = np.c_[test_data_first_column, test_data])\n",
    "\n",
    "num_train_machines = len(train_data[0].unique())\n",
    "num_test_machines = len(test_data[0].unique())\n",
    "\n",
    "# Process training and test data sepeartely as number of engines in training and test set may be different.\n",
    "# As we are doing scaling for full dataset, we are not bothered by different number of engines in training and test set.\n",
    "\n",
    "# Process trianing data\n",
    "for i in np.arange(1, num_train_machines + 1):\n",
    "    temp_train_data = train_data[train_data[0] == i].drop(columns = [0]).values\n",
    "    \n",
    "    # Verify if data of given window length can be extracted from training data\n",
    "    if (len(temp_train_data) < window_length):\n",
    "        print(\"Train engine {} doesn't have enough data for window_length of {}\".format(i, window_length))\n",
    "        raise AssertionError(\"Window length is larger than number of data points for some engines. \"\n",
    "                             \"Try decreasing window length.\")\n",
    "        \n",
    "    temp_train_targets = process_targets(data_length = temp_train_data.shape[0], early_rul = early_rul)\n",
    "    data_for_a_machine, targets_for_a_machine = process_input_data_with_targets(temp_train_data, temp_train_targets, \n",
    "                                                                                window_length = window_length, shift = shift)\n",
    "    \n",
    "    processed_train_data.append(data_for_a_machine)\n",
    "    processed_train_targets.append(targets_for_a_machine)\n",
    "\n",
    "processed_train_data = np.concatenate(processed_train_data)\n",
    "processed_train_targets = np.concatenate(processed_train_targets)\n",
    "\n",
    "# Process test data\n",
    "for i in np.arange(1, num_test_machines + 1):\n",
    "    temp_test_data = test_data[test_data[0] == i].drop(columns = [0]).values\n",
    "    \n",
    "    # Verify if data of given window length can be extracted from test data\n",
    "    if (len(temp_test_data) < window_length):\n",
    "        print(\"Test engine {} doesn't have enough data for window_length of {}\".format(i, window_length))\n",
    "        raise AssertionError(\"Window length is larger than number of data points for some engines. \"\n",
    "                             \"Try decreasing window length.\")\n",
    "    \n",
    "    # Prepare test data\n",
    "    test_data_for_an_engine, num_windows = process_test_data(temp_test_data, window_length = window_length, shift = shift,\n",
    "                                                             num_test_windows = num_test_windows)\n",
    "    \n",
    "    processed_test_data.append(test_data_for_an_engine)\n",
    "    num_test_windows_list.append(num_windows)\n",
    "\n",
    "processed_test_data = np.concatenate(processed_test_data)\n",
    "true_rul = true_rul[0].values\n",
    "\n",
    "# Shuffle training data\n",
    "index = np.random.permutation(len(processed_train_targets))\n",
    "processed_train_data, processed_train_targets = processed_train_data[index], processed_train_targets[index]\n",
    "\n",
    "print(\"Processed trianing data shape: \", processed_train_data.shape)\n",
    "print(\"Processed training ruls shape: \", processed_train_targets.shape)\n",
    "print(\"Processed test data shape: \", processed_test_data.shape)\n",
    "print(\"True RUL shape: \", true_rul.shape)\n",
    "\n",
    "print(type(processed_train_data))\n",
    "print(type(processed_test_data))\n",
    "print(type(processed_train_targets))\n",
    "print(type(true_rul))\n",
    "\n",
    "np.save(\"processed_test_data_np\",processed_test_data)\n",
    "np.save(\"processed_test_RUL_np\", true_rul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed train data shape:  (14184, 30, 14)\n",
      "Processed validation data shape:  (3547, 30, 14)\n",
      "Processed train targets shape:  (14184,)\n",
      "Processed validation targets shape:  (3547,)\n"
     ]
    }
   ],
   "source": [
    "processed_train_data, processed_val_data, processed_train_targets, processed_val_targets = train_test_split(processed_train_data,\n",
    "                                                                                                            processed_train_targets,\n",
    "                                                                                                            test_size = 0.2,\n",
    "                                                                                                            random_state = 83)\n",
    "print(\"Processed train data shape: \", processed_train_data.shape)\n",
    "print(\"Processed validation data shape: \", processed_val_data.shape)\n",
    "print(\"Processed train targets shape: \", processed_train_targets.shape)\n",
    "print(\"Processed validation targets shape: \", processed_val_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data(test_data_for_an_engine, window_length, shift, num_test_windows = 1):\n",
    "    \"\"\" This function takes test data for an engine as first input. The next two inputs\n",
    "    window_length and shift are same as other functins. \n",
    "    \n",
    "    Finally it takes num_test_windows as the last input. num_test_windows sets how many examplles we\n",
    "    want from test data (from last). By default it extracts only the last example.\n",
    "    \n",
    "    The function return last examples and number of last examples (a scaler) as output. \n",
    "    We need the second output later. If we are extracting more than 1 last examples, we have to \n",
    "    average their prediction results. The second scaler halps us do just that.\n",
    "    \"\"\"\n",
    "    max_num_test_batches = int(np.floor((len(test_data_for_an_engine) - window_length)/shift)) + 1\n",
    "    if max_num_test_batches < num_test_windows:\n",
    "        required_len = (max_num_test_batches -1)* shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, max_num_test_batches\n",
    "    else:\n",
    "        required_len = (num_test_windows - 1) * shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, num_test_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_targets(data_length, early_rul = None):\n",
    "    if early_rul == None:\n",
    "        return np.arange(data_length-1, -1, -1)\n",
    "    else:\n",
    "        early_rul_duration = data_length - early_rul\n",
    "        if early_rul_duration <= 0:\n",
    "            return np.arange(data_length-1, -1, -1)\n",
    "        else:\n",
    "            return np.append(early_rul*np.ones(shape = (early_rul_duration,)), np.arange(early_rul-1, -1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    alpha = 0.2\n",
    "    difference = y_pred - y_true\n",
    "    squared_difference = tf.square(y_pred - y_true)\n",
    "    \n",
    "    # Calcola la loss per ciascun elemento\n",
    "    loss = tf.where(difference < 0, 2 * alpha * squared_difference, 2 * (alpha + (1 - 2 * alpha)) * squared_difference)\n",
    "    \n",
    "    # Calcola la media delle loss\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a custom model\n",
    "class CreateModel(tf.keras.Model):\n",
    "    def __init__(self, input_shape, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.lstm_layer_1 = layers.LSTM(128, input_shape = input_shape, return_sequences = True, activation = \"tanh\")\n",
    "        self.lstm_layer_2 = layers.LSTM(64, activation = \"tanh\", return_sequences= True)\n",
    "        self.lstm_layer_3 = layers.LSTM(32, activation = \"tanh\")\n",
    "        self.dense_1 = layers.Dense(64, activation = \"relu\")\n",
    "        self.dense_2 = layers.Dense(96, activation = \"relu\")\n",
    "        self.dense_3 = layers.Dense(1)\n",
    "\n",
    "\n",
    "    def call(self, input_data, mask = None, **kwargs):\n",
    "        x = self.lstm_layer_1(input_data, mask = mask)\n",
    "        x = self.lstm_layer_2(x)\n",
    "        x = self.lstm_layer_3(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        return self.dense_3(x)\n",
    "    \n",
    "def create_compiled_model():\n",
    "    model = Sequential([\n",
    "        layers.LSTM(128, input_shape = (window_length, 14), return_sequences=True, activation = \"tanh\"),\n",
    "        layers.LSTM(64, activation = \"tanh\", return_sequences = True),\n",
    "        layers.LSTM(32, activation = \"tanh\"),\n",
    "        layers.Dense(64, activation = \"relu\"),\n",
    "        layers.Dense(96, activation = \"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(loss = custom_loss, optimizer = tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 09:36:32.029410: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-15 09:36:32.054849: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-15 09:36:32.054895: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-15 09:36:32.056153: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-15 09:36:32.056201: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-15 09:36:32.056228: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-15 09:36:32.300584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-15 09:36:32.300639: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-15 09:36:32.300647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-01-15 09:36:32.300686: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-15 09:36:32.300705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6701 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:07:00.0, compute capability: 6.1\n",
      "2024-01-15 09:36:32.853777: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "input_shape = (window_length, processed_train_data.shape[2])\n",
    "model = create_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    elif epoch >= 10 and epoch < 20 :\n",
    "        return 0.001\n",
    "    elif epoch >= 20 and epoch < 30: \n",
    "        return 0.0001\n",
    "    elif epoch >= 30: \n",
    "        return 0.00001\n",
    "    else: \n",
    "        return 0.01; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 09:36:49.279090: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2024-01-15 09:36:51.010552: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f14d40a1b60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-15 09:36:51.010587: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080, Compute Capability 6.1\n",
      "2024-01-15 09:36:51.060193: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-15 09:36:51.273177: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 9s 38ms/step - loss: 2648.3000 - val_loss: 1455.0353 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 571.2234 - val_loss: 204.9654 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 175.3408 - val_loss: 155.7304 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 1s 17ms/step - loss: 164.7385 - val_loss: 156.3085 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 150.4391 - val_loss: 147.6488 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 143.6174 - val_loss: 146.9662 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 141.2164 - val_loss: 145.4687 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 143.6787 - val_loss: 148.1265 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 141.4477 - val_loss: 147.1634 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 134.4200 - val_loss: 128.6411 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 129.6463 - val_loss: 128.6555 - lr: 0.0010\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 131.0470 - val_loss: 133.6035 - lr: 0.0010\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 126.0169 - val_loss: 120.1949 - lr: 0.0010\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 1s 18ms/step - loss: 123.9396 - val_loss: 124.5125 - lr: 0.0010\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 124.1737 - val_loss: 116.7287 - lr: 0.0010\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 123.8460 - val_loss: 120.4687 - lr: 0.0010\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 119.9273 - val_loss: 124.1670 - lr: 0.0010\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 121.1530 - val_loss: 110.9498 - lr: 0.0010\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 114.0508 - val_loss: 115.5569 - lr: 0.0010\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 111.5663 - val_loss: 119.3805 - lr: 0.0010\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 104.0629 - val_loss: 102.3010 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 100.7344 - val_loss: 101.1073 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 99.7282 - val_loss: 100.1231 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 98.2502 - val_loss: 98.4638 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 98.6635 - val_loss: 97.6006 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 96.9748 - val_loss: 96.3713 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 95.8471 - val_loss: 97.7819 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 95.7413 - val_loss: 96.3534 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 94.1872 - val_loss: 95.2716 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 93.5299 - val_loss: 94.1426 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 91.1771 - val_loss: 92.9378 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 90.1940 - val_loss: 92.8771 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 90.1716 - val_loss: 92.6397 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 90.0952 - val_loss: 92.4999 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 89.9015 - val_loss: 92.8166 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 89.7316 - val_loss: 92.5805 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 89.6237 - val_loss: 92.3253 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 89.5169 - val_loss: 92.4600 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 1s 23ms/step - loss: 89.4233 - val_loss: 92.3271 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 89.4424 - val_loss: 92.4861 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 89.1413 - val_loss: 92.0634 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 89.0599 - val_loss: 92.2677 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 88.8277 - val_loss: 92.4167 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 88.8357 - val_loss: 91.7533 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 88.7143 - val_loss: 92.0257 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 88.5331 - val_loss: 91.7075 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 88.4236 - val_loss: 91.6323 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 88.3234 - val_loss: 91.9544 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 88.1289 - val_loss: 91.6471 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 1s 22ms/step - loss: 88.0184 - val_loss: 91.0951 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50 \n",
    "BATCH_SIZE = 256\n",
    "\n",
    "history = model.fit(processed_train_data, processed_train_targets, epochs = EPOCHS, \n",
    "                    validation_data = (processed_val_data, processed_val_targets), \n",
    "                    callbacks = callback, \n",
    "                    batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 8ms/step\n",
      "RMSE:  15.078168869774917\n"
     ]
    }
   ],
   "source": [
    "rul_pred = model.predict(processed_test_data).reshape(-1)\n",
    "preds_for_each_engine = np.split(rul_pred, np.cumsum(num_test_windows_list)[:-1])\n",
    "mean_pred_for_each_engine = [np.average(ruls_for_each_engine, weights = np.repeat(1/num_windows, num_windows)) \n",
    "                             for ruls_for_each_engine, num_windows in zip(preds_for_each_engine, num_test_windows_list)]\n",
    "RMSE = np.sqrt(mean_squared_error(true_rul, mean_pred_for_each_engine))\n",
    "print(\"RMSE: \", RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Taking only last examples):  16.289365586424736\n"
     ]
    }
   ],
   "source": [
    "indices_of_last_examples = np.cumsum(num_test_windows_list) - 1\n",
    "preds_for_last_example = np.concatenate(preds_for_each_engine)[indices_of_last_examples]\n",
    "\n",
    "RMSE_new = np.sqrt(mean_squared_error(true_rul, preds_for_last_example))\n",
    "print(\"RMSE (Taking only last examples): \", RMSE_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_s_score(rul_true, rul_pred):\n",
    "    \"\"\"\n",
    "    Both rul_true and rul_pred should be 1D numpy arrays.\n",
    "    \"\"\"\n",
    "    diff = rul_pred - rul_true\n",
    "    return np.sum(np.where(diff < 0, np.exp(-diff/13)-1, np.exp(diff/10)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-score (LARGE MODEL MSE):  366.61679547071185\n"
     ]
    }
   ],
   "source": [
    "s_score = compute_s_score(true_rul, preds_for_last_example)\n",
    "print(\"S-score (LARGE MODEL MSE): \", s_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "motor_indices = np.arange(100)\n",
    "bar_width = 0.60\n",
    "plt.bar(motor_indices, true_rul, bar_width, label=\"True RUL\", color=\"red\")\n",
    "plt.bar(motor_indices + bar_width , preds_for_last_example, bar_width, label=\"Pred RUL\", color=\"blue\")\n",
    "# Aggiungere legenda e mostrare il grafico\n",
    "plt.legend()\n",
    "plt.xlabel(\"Motori\")\n",
    "plt.ylabel(\"RUL Values\")\n",
    "plt.title(\"Confronto diretto tra True e Predicted RUL per motore\")\n",
    "plt.savefig(\"alternative_LSTM.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
